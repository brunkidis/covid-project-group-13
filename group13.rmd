---
title: "Covid Project Group 13"
output:
  html_document:
    number_sections: yes
    toc: yes  
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}


#install libraries, uncomment lines below if packages are already installed
#install.packages("dplyr")
#install.packages("ggplot2")
#install.packages("tidyverse")
#install.packages("janitor")
#install.packages("gganimate")
#install.packages("gifski")
#install.packages("png")
#install.packages("ggrepel")
#install.packages("scales")
#install.packages("RCurl")

library(dplyr)
library(ggplot2)
library(tidyverse)
library(janitor)
library(gganimate)
library(gifski)
library(png)
library(ggrepel)
library(scales)
library(RCurl)

combined_data = read.csv(file = "combinedData.csv")

# obtain up to date data for daily cases automatically
timeline <- read.csv(text = getURL(
  "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv"
  ))
```

### Group 13's Goals

Our group chose to analyze two different trends in the data from JHU's Covid Dataset, both trying to evaluate correlation, but one looking at data over time, and the other as a summary to date.

1. For our first hypothesis we wanted to test if major holidays or turning points contributed to a rise in the number of cases of coronavirus in the US.

2. For our second hypothesis we wanted to analyze how a region's political affiliation impacted an individual's likelihood to have contracted or been exposed to coronavirus.

## Important Days and Case Increases

Overview ...

Following Key dates, is there a spike in the following 1-2 weeks after these events?

- Timeline
- Key dates
- Correlation

```{r}

# First we will look at the overall timeline for the US.
cases <- timeline %>% select(seq(12, length(timeline)))
totals <- cases %>% summarize_at(vars(2:length(cases)), sum)
total_list <- data.matrix(totals)
new_cases <- c()
# convert from total cases to new cases
for (i in seq(2, length(total_list))) {
  new_cases <- c(new_cases, (total_list[i] - total_list[i-1]))
}
plot(new_cases, type="l")

```
```{r}
# we can also plot this graph's derivative to see where the number of new cases was increasing
# plotting differences in day to day new cases isn't useful since the rate of change oscillates daily
# let's plot differences between 1 week intervals to see more long term trends
rate_of_change <- c()
for (i in seq(15, length(new_cases))) {
  rate_of_change <- c(rate_of_change, sum(new_cases[(i-7):(i)]) - sum(new_cases[(i-14):(i-7)]))
}
plot(rate_of_change, type="l")
abline(h=0)

# haloween, election day, and veterans day all occur in a 2-week time peridos, so we group them together starting from Haloween

# Note that case numbers following Thanksgiving may not be fully updated by the time of the presentation

holidays <- c("Easter", "Memorial Day", "Independence Day", "Labor Day",  "Haloween", "Thanksgiving")
dates <- c("2020-04-12", "2020-05-25","2020-07-04", "2020-09-07",  "2020-10-31", "2020-11-26")
start_date <- "2020-01-23"
# create 2 week intervals following each holiday

for (day in dates) {
  
  abline(v=as.Date(day)-as.Date(start_date)-15)
  # plot the line graph for this interval
}

#plot the zeroes of the derivative
#dates <- seq(from=as.Date(start_date), by="day", length.out=length(totals))

#zeroes <-dates[rate_of_change <= 10 && rate_of_change >= -10]
```

```{r}

# Try to make a scatter plot: days passed since holiday vs % of new cases in that period

```

Key takeaways

## Political Affilitation and Likelihood of Contracting Coronavirus

Overview ...

- Scatter Plot
- Linear Regression
- Clustering

```{r}
# Remove Outliers (remove if outliers are wanted)
#cases <- combined_data$Cases
#cases_Q1 <- quantile(cases, 0.25)
#cases_Q3 <- quantile(cases, 0.75)
#cases_IQR <- IQR(cases)
# adjust 1.5 to 3 to remove only extreme outliers
#combined_data_no_out <- subset(combined_data, cases> (cases_Q1 - 1.5*cases_IQR) & cases< (cases_Q3 + 1.5*cases_IQR))

# Grab data from sets (change combined_data_no_out to combined_data to use set with outliers)
#cases <- combined_data_no_out$Cases
#percent_gop <- combined_data_no_out$per_gop
#percent_dem <- combined_data_no_out$per_dem

# Plot the scatterplots (seperately, they appear too squished if together)
#plot(percent_gop, cases, col = "red", xlab = "Percentage of Population Voting Republican", ylab = "Number of Cases")
#plot(percent_dem, cases, col = "blue", xlab = "Percentage of Population Voting Democrat", ylab = "Number of Cases")



##correction for plots USE THIS INSTEAD delete above stuff when data is corrected and you're sure this works
combined_data <- transform(combined_data, cases_per_pop = Cases / as.integer(Population))
cases_per_pop <- combined_data$cases_per_pop
percent_gop <- combined_data$per_gop
percent_dem <- combined_data$per_dem


#all data should be between 0 and 1, make sure it is
#if there are random outliers and data is correct!! add ylim=c(0,1) to both graphs
plot(percent_gop, cases_per_pop, col = "red", xlab = "Percentage of Population Voting Republican", ylab = "Cases as Percent of Population")
abline(lm(cases_per_pop ~ percent_gop), col ="blue")

plot(percent_dem, cases_per_pop, col = "blue", xlab = "Percentage of Population Voting Democrat", ylab = "Cases as Percent of Population")
abline(lm(cases_per_pop ~ percent_dem), col = "red")

# correlation values between percent gop, dem and cases/pop
final = data.frame("cases.pop" = cases_per_pop, "pecent.dem" = percent_dem, "percent.gop" = percent_gop)

cor(final, use = "complete.obs")

```

Key takeaways

## References

Source out all our data
